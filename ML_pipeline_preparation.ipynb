{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Here I create a machine learning pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "The steps I will folow will be: \n",
    "- Import the necessary Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/michaelreinhardme.com/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/michaelreinhardme.com/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/michaelreinhardme.com/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/michaelreinhardme.com/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/michaelreinhardme.com/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/michaelreinhardme.com/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import re\n",
    "import sqlalchemy \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.stem import *\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, multilabel_confusion_matrix, make_scorer, f1_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.4.4.\n",
      "The sklearn version is 0.21.2\n"
     ]
    }
   ],
   "source": [
    "print(f'The nltk version is {nltk.__version__}.')\n",
    "# print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "print(f'The sklearn version is {sklearn.__version__}')\n",
    "# print(f'The version of pickle is {pickle.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I load the data from the database\n",
    "#sqlite:///\n",
    "engine = sqlalchemy.create_engine('sqlite:///data/DisasterResponse.db')\n",
    "\n",
    "#read it into a Pandas DataFrame\n",
    "df = pd.read_sql_table('disaster', engine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26172</th>\n",
       "      <td>30261</td>\n",
       "      <td>The training demonstrated how to enhance micro...</td>\n",
       "      <td>None</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26173</th>\n",
       "      <td>30262</td>\n",
       "      <td>A suitable candidate has been selected and OCH...</td>\n",
       "      <td>None</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26174</th>\n",
       "      <td>30263</td>\n",
       "      <td>Proshika, operating in Cox's Bazar municipalit...</td>\n",
       "      <td>None</td>\n",
       "      <td>news</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26175</th>\n",
       "      <td>30264</td>\n",
       "      <td>Some 2,000 women protesting against the conduc...</td>\n",
       "      <td>None</td>\n",
       "      <td>news</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26176</th>\n",
       "      <td>30265</td>\n",
       "      <td>A radical shift in thinking came about as a re...</td>\n",
       "      <td>None</td>\n",
       "      <td>news</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            message original  \\\n",
       "26172  30261  The training demonstrated how to enhance micro...     None   \n",
       "26173  30262  A suitable candidate has been selected and OCH...     None   \n",
       "26174  30263  Proshika, operating in Cox's Bazar municipalit...     None   \n",
       "26175  30264  Some 2,000 women protesting against the conduc...     None   \n",
       "26176  30265  A radical shift in thinking came about as a re...     None   \n",
       "\n",
       "      genre  related  request  offer  aid_related  medical_help  \\\n",
       "26172  news        0        0      0            0             0   \n",
       "26173  news        0        0      0            0             0   \n",
       "26174  news        1        0      0            0             0   \n",
       "26175  news        1        0      0            1             0   \n",
       "26176  news        1        0      0            0             0   \n",
       "\n",
       "       medical_products  ...  aid_centers  other_infrastructure  \\\n",
       "26172                 0  ...            0                     0   \n",
       "26173                 0  ...            0                     0   \n",
       "26174                 0  ...            0                     0   \n",
       "26175                 0  ...            0                     0   \n",
       "26176                 0  ...            0                     0   \n",
       "\n",
       "       weather_related  floods  storm  fire  earthquake  cold  other_weather  \\\n",
       "26172                0       0      0     0           0     0              0   \n",
       "26173                0       0      0     0           0     0              0   \n",
       "26174                0       0      0     0           0     0              0   \n",
       "26175                0       0      0     0           0     0              0   \n",
       "26176                0       0      0     0           0     0              0   \n",
       "\n",
       "       direct_report  \n",
       "26172              0  \n",
       "26173              0  \n",
       "26174              0  \n",
       "26175              0  \n",
       "26176              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26177, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 26,177 observations and 40 variables, just like in the last notebook. Which is good. \n",
    "\n",
    "Starting with the fifth (zero based indexing) column, 'request', till the 40th, the variables represent a one-hot encoding of message classifications. There are qualitative variables, 'genre' and 'related', that are we are going to leave out of our analysis for the time being. The 'original' messages is just that, the original message, often in a foreign language. \n",
    "\n",
    "Now we get the value counts of the qualitative variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value counts for \"genre\" are:\n",
      "news      13036\n",
      "direct    10747\n",
      "social     2394\n",
      "Name: genre, dtype: int64\n",
      "\n",
      "the value counts for \"related\" are:\n",
      "1    19873\n",
      "0     6117\n",
      "2      187\n",
      "Name: related, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ['genre','related']:\n",
    "    print(f'the value counts for \"{i}\" are:\\n{df[i].value_counts()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into independent and dependent variables\n",
    "For the independent variable we are going to use the message itself. For the dependent variable we are going to use the 35 categorizations of the messages. Thus the usual situation where there are numerous independent variable and one dependent variable is, for the time being, reversed. We will subsequently, in the process of turning the text content of 'message' into analyzable data, greatly increase the dimensionality of the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,'message']\n",
    "y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26177,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26177, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers',\n",
       "       'other_infrastructure', 'weather_related', 'floods', 'storm',\n",
       "       'fire', 'earthquake', 'cold', 'other_weather', 'direct_report'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4463\n",
      "118\n",
      "10841\n",
      "2081\n",
      "1312\n",
      "723\n",
      "471\n",
      "858\n",
      "0\n",
      "1669\n",
      "2917\n",
      "2309\n",
      "404\n",
      "603\n",
      "298\n",
      "874\n",
      "1192\n",
      "3439\n",
      "1701\n",
      "1198\n",
      "1329\n",
      "532\n",
      "159\n",
      "283\n",
      "120\n",
      "309\n",
      "1147\n",
      "7283\n",
      "2148\n",
      "2440\n",
      "282\n",
      "2452\n",
      "529\n",
      "1373\n",
      "5066\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns[5:]:\n",
    "    print(y[i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data needed for visuals, first graph\n",
    "genre_proportions = df.groupby('genre').count()['message']/len(df)\n",
    "genre_names = list(genre_proportions.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
       "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
       "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
       "       'missing_people', 'refugees', 'death', 'other_aid',\n",
       "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
       "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
       "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
       "       'other_weather', 'direct_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cd5a45c18>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_values = []\n",
    "y_values = []\n",
    "for i in df.columns[4:]:\n",
    "    x_values.append(i)\n",
    "    y_values.append(df[i].sum()/len(df))\n",
    "    \n",
    "plt.plot(x_values, y_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "pstemmer = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "url_regex = 'http[s]?://(?:[a-zA-Z][0-9]|[$-_@.&+]|[!*\\(\\),]|[?:%[0-9a-fA-F][0-9a-fA-F])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, lemmatize='l'):\n",
    "    #remove urs and replace with placeholder\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, 'url_placeholder')\n",
    "    \n",
    "    #normalize case and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    #tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    if lemmatize=='l':\n",
    "        #lemmatize andremove stop words\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    if lemmatize=='p':\n",
    "        #stem the works\n",
    "        tokens = [pstemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    if lemmatize=='lp':\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        tokens = [pstemmer.stem(word) for word in tokens]\n",
    "\n",
    "    if lemmatize=='pl':\n",
    "        tokens = [pstemmer.stem(word) for word in tokens]\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        \n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokenized = X.apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [weather, update, cold, front, cuba, could, pa...\n",
      "1                                          [hurricane]\n",
      "2                             [looking, someone, name]\n",
      "3    [un, report, leogane, 80, 90, destroyed, hospi...\n",
      "4    [say, west, side, haiti, rest, country, today,...\n",
      "Name: message, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex(start=0, stop=26177, step=1)\n",
      "[list(['weather', 'update', 'cold', 'front', 'cuba', 'could', 'pas', 'haiti'])\n",
      " list(['hurricane'])]\n",
      "(26177,)\n"
     ]
    }
   ],
   "source": [
    "print(X_tokenized.head())\n",
    "print(type(X_tokenized))\n",
    "print(X_tokenized.index)\n",
    "print(X_tokenized.values[:2])\n",
    "print(X_tokenized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't use `X_tokenized` in the analysis but create it to better understand what is going on. So we see that `X_tokenized` is a list pandas Series of lists, each list containing the words in a tweet. Since the list is still just counted as one object the size of the data set has not increased. We can see the effects of lemmatization and stemming in words like 'hurrican' and 'updat'. This will reduce the number of words that the algorithm has to deal will. Lowering the dimensionality of the data set will reduce the noise that that goes into the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list[0]:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "            \n",
    "            \n",
    "        return False\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#     ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "# ])\n",
    "\n",
    "# 'clf__estimator__max_features': 'log2',\n",
    "#  'clf__estimator__min_samples_split': 2,\n",
    "#  'clf__estimator__n_estimators': 250,\n",
    "#  'vect__ngram_range': (1, 2)}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(\\\n",
    "                    RandomForestClassifier(\\\n",
    "                        random_state=100, n_estimators=250,\\ \n",
    "                        min_samples_split=2,\\\n",
    "                        max_features='log2')))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abortive attempt at constucting a loop to test the different settings for tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = ['l','p','lp','pl','']\n",
    "\n",
    "# for i in options:\n",
    "#     tokenize = tokenize(X_train, lemmatize=i)\n",
    "#     pipeline.fit(X_train, y_train)\n",
    "#     y_pred = pipeline.predict(X_test)\n",
    "#     print(accuracy_score(y_test, y_pred))\n",
    "#     print(f'the accurracy score for tokenise {i} = {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not been able to get the `FeatureUnion` feature to work so I am leaving it out for now, though I would like to include it in future versions. The `StartingVerbExtractor` doesn't seem all that vital but I could be wrong. Also, I would like to include the quantitative variables 'genre' and 'related' in the analysis, though I don't think that will require `FeatureUnion`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline1 = Pipeline([\n",
    "#     ('features', FeatureUnion([\n",
    "\n",
    "#         ('text_pipeline', Pipeline([\n",
    "#             ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#             ('tfidf', TfidfTransformer())\n",
    "#         ])),\n",
    "\n",
    "#         ('starting_verb', StartingVerbExtractor())\n",
    "#     ])),\n",
    "\n",
    "#     ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    \n",
    "#     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=None,\n",
       "                                                                        max_features='log2',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estimators=250,\n",
       "                                                                        n_jobs=None,\n",
       "                                                                        oob_score=False,\n",
       "                                                                        random_state=100,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6545, 36)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b123e04c5193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for just lemmatizing the text I got 0.384 accuracy. For just stemming I got 0.378. For stemming and then lemmatizing I got 0.383. And for lemmatising and then stemming I got 0.384 again. For reference, skipping both lemmatizing and stemming got 0.385, so on this evidence it is best to not use either. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this dry run of running random forest without any parameter tuning does just 38% accuracy. That is not very good, though there were 35 categories into which a message could be categorized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-8aa1f0ed8011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1850\u001b[0m     \"\"\"\n\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=y_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-356701dd6a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \"\"\"\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "multilabel_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9381291910703675\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(pipeline, X_test, y_test, category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'vect', 'tfidf', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__preprocessor', 'vect__stop_words', 'vect__strip_accents', 'vect__token_pattern', 'vect__tokenizer', 'vect__vocabulary', 'tfidf__norm', 'tfidf__smooth_idf', 'tfidf__sublinear_tf', 'tfidf__use_idf', 'clf__estimator__bootstrap', 'clf__estimator__class_weight', 'clf__estimator__criterion', 'clf__estimator__max_depth', 'clf__estimator__max_features', 'clf__estimator__max_leaf_nodes', 'clf__estimator__min_impurity_decrease', 'clf__estimator__min_impurity_split', 'clf__estimator__min_samples_leaf', 'clf__estimator__min_samples_split', 'clf__estimator__min_weight_fraction_leaf', 'clf__estimator__n_estimators', 'clf__estimator__n_jobs', 'clf__estimator__oob_score', 'clf__estimator__random_state', 'clf__estimator__verbose', 'clf__estimator__warm_start', 'clf__estimator', 'clf__n_jobs'])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_M(text, lemma=True, remove_stop=True, remove_short=True):\n",
    "    '''\n",
    "    input: (\n",
    "        text: \n",
    "        lemma: True if lemmatize word, \n",
    "        remove_stop: True if remove stopwords  \n",
    "        remove_short: True if remove short words > 2\n",
    "            )\n",
    "    Function tokenizes the text \n",
    "    output: (\n",
    "        returns cleaned tokens in list \n",
    "            )\n",
    "    '''\n",
    "    # stopword list \n",
    "    STOPWORDS = list(set(stopwords.words('english')))\n",
    "    # initialize lemmatier\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # split string into words (tokens)\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove short words\n",
    "    if remove_short: tokens = [token for token in tokens if len(token) > 2]\n",
    "    # put words into base form\n",
    "    if lemma: tokens = [lemmatizer.lemmatize(token).lower().strip() for token in tokens]\n",
    "    # remove stopwords\n",
    "    if remove_stop: tokens = [token for token in tokens if token not in STOPWORDS]\n",
    "    # return data \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#     ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "# ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize_M)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(random_state=100)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'vect', 'tfidf', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__preprocessor', 'vect__stop_words', 'vect__strip_accents', 'vect__token_pattern', 'vect__tokenizer', 'vect__vocabulary', 'tfidf__norm', 'tfidf__smooth_idf', 'tfidf__sublinear_tf', 'tfidf__use_idf', 'clf__estimator__bootstrap', 'clf__estimator__class_weight', 'clf__estimator__criterion', 'clf__estimator__max_depth', 'clf__estimator__max_features', 'clf__estimator__max_leaf_nodes', 'clf__estimator__min_impurity_decrease', 'clf__estimator__min_impurity_split', 'clf__estimator__min_samples_leaf', 'clf__estimator__min_samples_split', 'clf__estimator__min_weight_fraction_leaf', 'clf__estimator__n_estimators', 'clf__estimator__n_jobs', 'clf__estimator__oob_score', 'clf__estimator__random_state', 'clf__estimator__verbose', 'clf__estimator__warm_start', 'clf__estimator', 'clf__n_jobs'])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#         'tfidf__smooth_idf': [True, False],\n",
    "#         'clf__estimator__n_estimators': [20, 25],\n",
    "#         'clf__estimator__max_depth' : [1, 2, 3]\n",
    "#     }\n",
    "param_grid = {\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'clf__estimator__min_samples_split': [2, 4],\n",
    "        'clf__estimator__max_features': ['log2', 'auto'],\n",
    "        'clf__estimator__n_estimators': [100, 250],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(pipeline, param_grid=param_grid, verbose=2, n_jobs=4, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 306.4min\n",
      "[Parallel(n_jobs=4)]: Done  48 out of  48 | elapsed: 436.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        tok...\n",
       "                                                                                               random_state=100,\n",
       "                                                                                               verbose=0,\n",
       "                                                                                               warm_start=False),\n",
       "                                                              n_jobs=None))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid={'clf__estimator__max_features': ['log2', 'auto'],\n",
       "                         'clf__estimator__min_samples_split': [2, 4],\n",
       "                         'clf__estimator__n_estimators': [100, 250],\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__max_features': 'log2',\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__n_estimators': 250,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cv.predict(X_test)\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4343773873185638\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.88      0.35      0.50      1130\n",
      "                 offer       0.00      0.00      0.00        32\n",
      "           aid_related       0.86      0.39      0.54      2734\n",
      "          medical_help       0.40      0.00      0.01       535\n",
      "      medical_products       0.75      0.01      0.02       318\n",
      "     search_and_rescue       0.00      0.00      0.00       180\n",
      "              security       0.00      0.00      0.00       117\n",
      "              military       0.00      0.00      0.00       205\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       1.00      0.09      0.16       430\n",
      "                  food       0.90      0.20      0.33       715\n",
      "               shelter       0.96      0.04      0.08       598\n",
      "              clothing       0.33      0.01      0.02        87\n",
      "                 money       0.80      0.03      0.05       141\n",
      "        missing_people       0.00      0.00      0.00        65\n",
      "              refugees       0.00      0.00      0.00       246\n",
      "                 death       1.00      0.02      0.04       314\n",
      "             other_aid       0.60      0.01      0.02       858\n",
      "infrastructure_related       0.00      0.00      0.00       465\n",
      "             transport       0.00      0.00      0.00       285\n",
      "             buildings       1.00      0.01      0.01       355\n",
      "           electricity       0.00      0.00      0.00       125\n",
      "                 tools       0.00      0.00      0.00        35\n",
      "             hospitals       0.00      0.00      0.00        77\n",
      "                 shops       0.00      0.00      0.00        46\n",
      "           aid_centers       0.00      0.00      0.00        84\n",
      "  other_infrastructure       0.00      0.00      0.00       306\n",
      "       weather_related       0.90      0.29      0.44      1770\n",
      "                floods       0.75      0.01      0.02       495\n",
      "                 storm       0.82      0.03      0.06       605\n",
      "                  fire       0.00      0.00      0.00        68\n",
      "            earthquake       0.87      0.30      0.45       589\n",
      "                  cold       1.00      0.01      0.01       133\n",
      "         other_weather       0.67      0.01      0.01       320\n",
      "         direct_report       0.88      0.25      0.39      1260\n",
      "\n",
      "             micro avg       0.87      0.17      0.29     15723\n",
      "             macro avg       0.44      0.06      0.09     15723\n",
      "          weighted avg       0.71      0.17      0.26     15723\n",
      "           samples avg       0.23      0.10      0.13     15723\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))\n",
    "print(print(classification_report(y_test, y_pred, target_names=y_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request\n",
      "[[5363   52]\n",
      " [ 731  399]]\n",
      "offer\n",
      "[[6513    0]\n",
      " [  32    0]]\n",
      "aid_related\n",
      "[[3637  174]\n",
      " [1667 1067]]\n",
      "medical_help\n",
      "[[6007    3]\n",
      " [ 533    2]]\n",
      "medical_products\n",
      "[[6226    1]\n",
      " [ 315    3]]\n",
      "search_and_rescue\n",
      "[[6363    2]\n",
      " [ 180    0]]\n",
      "security\n",
      "[[6428    0]\n",
      " [ 117    0]]\n",
      "military\n",
      "[[6339    1]\n",
      " [ 205    0]]\n",
      "child_alone\n",
      "[[6545]]\n",
      "water\n",
      "[[6115    0]\n",
      " [ 392   38]]\n",
      "food\n",
      "[[5814   16]\n",
      " [ 573  142]]\n",
      "shelter\n",
      "[[5946    1]\n",
      " [ 572   26]]\n",
      "clothing\n",
      "[[6456    2]\n",
      " [  86    1]]\n",
      "money\n",
      "[[6403    1]\n",
      " [ 137    4]]\n",
      "missing_people\n",
      "[[6480    0]\n",
      " [  65    0]]\n",
      "refugees\n",
      "[[6299    0]\n",
      " [ 246    0]]\n",
      "death\n",
      "[[6231    0]\n",
      " [ 307    7]]\n",
      "other_aid\n",
      "[[5681    6]\n",
      " [ 849    9]]\n",
      "infrastructure_related\n",
      "[[6080    0]\n",
      " [ 465    0]]\n",
      "transport\n",
      "[[6260    0]\n",
      " [ 285    0]]\n",
      "buildings\n",
      "[[6190    0]\n",
      " [ 353    2]]\n",
      "electricity\n",
      "[[6420    0]\n",
      " [ 125    0]]\n",
      "tools\n",
      "[[6510    0]\n",
      " [  35    0]]\n",
      "hospitals\n",
      "[[6468    0]\n",
      " [  77    0]]\n",
      "shops\n",
      "[[6499    0]\n",
      " [  46    0]]\n",
      "aid_centers\n",
      "[[6461    0]\n",
      " [  84    0]]\n",
      "other_infrastructure\n",
      "[[6239    0]\n",
      " [ 306    0]]\n",
      "weather_related\n",
      "[[4717   58]\n",
      " [1255  515]]\n",
      "floods\n",
      "[[6048    2]\n",
      " [ 489    6]]\n",
      "storm\n",
      "[[5936    4]\n",
      " [ 587   18]]\n",
      "fire\n",
      "[[6477    0]\n",
      " [  68    0]]\n",
      "earthquake\n",
      "[[5930   26]\n",
      " [ 410  179]]\n",
      "cold\n",
      "[[6412    0]\n",
      " [ 132    1]]\n",
      "other_weather\n",
      "[[6224    1]\n",
      " [ 318    2]]\n",
      "direct_report\n",
      "[[5243   42]\n",
      " [ 940  320]]\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(y_test.columns):\n",
    "    print(label)\n",
    "    print(confusion_matrix(y_test.values[:,i], y_pred[:,i]))\n",
    "#     if i == 4:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = y_test.columns\n",
    "def evaluate_model(cv, X_test, y_test, category_names):\n",
    "    '''\n",
    "    input: (\n",
    "        model: trained model \n",
    "        X_test: Test features \n",
    "        Y_test: Test labels \n",
    "        category_names: names of lables\n",
    "            )\n",
    "    Evaluate a trained model against a test dataset\n",
    "    '''\n",
    "    # get predictions \n",
    "    y_preds = cv.predict(X_test)\n",
    "    # print classification report\n",
    "#     print(classification_report(y_preds, y_test.values, target_names=category_names))\n",
    "    # print raw accuracy score \n",
    "    print('Accuracy Score: {}'.format(np.mean(y_test.values == y_preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.35      0.88      0.50       451\n",
      "                 offer       0.00      0.00      0.00         0\n",
      "           aid_related       0.39      0.86      0.54      1241\n",
      "          medical_help       0.00      0.40      0.01         5\n",
      "      medical_products       0.01      0.75      0.02         4\n",
      "     search_and_rescue       0.00      0.00      0.00         2\n",
      "              security       0.00      0.00      0.00         0\n",
      "              military       0.00      0.00      0.00         1\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.09      1.00      0.16        38\n",
      "                  food       0.20      0.90      0.33       158\n",
      "               shelter       0.04      0.96      0.08        27\n",
      "              clothing       0.01      0.33      0.02         3\n",
      "                 money       0.03      0.80      0.05         5\n",
      "        missing_people       0.00      0.00      0.00         0\n",
      "              refugees       0.00      0.00      0.00         0\n",
      "                 death       0.02      1.00      0.04         7\n",
      "             other_aid       0.01      0.60      0.02        15\n",
      "infrastructure_related       0.00      0.00      0.00         0\n",
      "             transport       0.00      0.00      0.00         0\n",
      "             buildings       0.01      1.00      0.01         2\n",
      "           electricity       0.00      0.00      0.00         0\n",
      "                 tools       0.00      0.00      0.00         0\n",
      "             hospitals       0.00      0.00      0.00         0\n",
      "                 shops       0.00      0.00      0.00         0\n",
      "           aid_centers       0.00      0.00      0.00         0\n",
      "  other_infrastructure       0.00      0.00      0.00         0\n",
      "       weather_related       0.29      0.90      0.44       573\n",
      "                floods       0.01      0.75      0.02         8\n",
      "                 storm       0.03      0.82      0.06        22\n",
      "                  fire       0.00      0.00      0.00         0\n",
      "            earthquake       0.30      0.87      0.45       205\n",
      "                  cold       0.01      1.00      0.01         1\n",
      "         other_weather       0.01      0.67      0.01         3\n",
      "         direct_report       0.25      0.88      0.39       362\n",
      "\n",
      "             micro avg       0.17      0.87      0.29      3133\n",
      "             macro avg       0.06      0.44      0.09      3133\n",
      "          weighted avg       0.32      0.87      0.46      3133\n",
      "           samples avg       0.10      0.23      0.13      3133\n",
      "\n",
      "Accuracy Score: 0.9416173742224162\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(cv, X_test, y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#     ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', MultiOutputClassifier(xgb.XGBClassifier()))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#         'vect__max_features': [1000, 1500, 2000],\n",
    "#         'tfidf__norm': ['l2'],\n",
    "#         'tfidf__sublinear_tf': [ False],\n",
    "#         'tfidf__smooth_idf': [False],\n",
    "#         'clf__estimator__max_depth': [3,5]\n",
    "#     }\n",
    "\n",
    "# cv = GridSearchCV(pipeline, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, label in enumerate(y_test.columns):\n",
    "#     print(label)\n",
    "#     print(confusion_matrix(y_test.values[:,i], y_pred[:,i] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_model = 'models/finalized_model.sav'\n",
    "pickle.dump(cv, open(disaster_model, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
